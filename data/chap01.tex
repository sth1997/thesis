\chapter{引言}
\label{chap1}

\section{研究背景}
稀疏矩阵一般是指矩阵中的零元数目远远多于非零元数目，且零元的分布无规律的矩阵。稀疏矩阵在传统的科学计算以及新兴的深度学习等众多领域都有着广泛的应用。本文主要关注稀疏矩阵在深度学习的分布式训练中的应用于优化。

目前，深度学习在计算机视觉、自然语言理解以及语音识别等多方面都有着重要的应用，并且取得了非常显著的效果。在深度神经网络研究初期，研究人员无法构造出深度较深、参数较多的神经网络，因为这种比较大的神经网络存在梯度消失与梯度爆炸~\cite{bengio1994learning, glorot2010understanding}等一系列问题，导致深度较深的网络难以收敛。直到Resnet~\cite{he2016deep}网路的出现，它为构造出层数和参数更多的神经网络提供了可能，同时也证明了在一定条件下，神经网络的深度越深、参数越多，取得的精度就越高，效果也就越好。

虽然参数量大的神经网络可以拥有更好的效果，但是这也引入了新的问题---训练时间长。神经网络的训练过程包括正向传播与反向传播这两个部分，它们都需要非常大的计算量，这就使得模型的训练时间变得很长。为了缩短训练时间，就需要使用更多计算资源。单一机器的计算资源是有限的，所以为了能够使用更多计算资源来达到大幅度缩短训练时间的效果，就需要使用集群进行分布式训练。

在神经网络的训练中，反向传播算法会根据输入的数据以及正向传播算法得到的结果，算出每个参数的梯度，并用梯度来更新参数、迭代模型。若是分布式训练，则需要调用Allreduce算法~\cite{rabenseifner2004optimization,bruck1997efficient}来将所有进程中的梯度求和并取平均值，用此平均梯度来更新参数、迭代模型，这样就可以保证各进程的模型参数在每轮训练开始时都是相同的。

分布式训练在一定程度上使神经网络训练的计算速度变得更快，但是由于Allreduce过程的存在，也同样引入了额外的网络通信开销。并且，由于一般只有较大的网络才会使用分布式训练，而较大的网络拥有大量参数，这使得分布式训练中网络带宽成为训练瓶颈，在网络环境较差的情况下，分布式训练中网络通信的时间占总训练时间的比例甚至会超过50\%。对于移动设备上的神经网络训练，网络带宽问题将变得更为严重，比如由谷歌提出的联合学习~\cite{federatedLearning}。因此，减少训练中的通信时间并加速Allreduce算法，对于加速神经网络分布式训练而言尤为重要。

为了减少分布式训练的通信时间，研究人员提出了多种神经网络模型的裁剪技术~\cite{strom2015scalable, han2015deep, lin2017deep}。这些技术的目标大多是在保证模型精度不变或精度略微降低的情况下，对模型进行压缩，减少网络通信量。

\section{本文的主要研究内容}
我们的工作基于深度梯度压缩技术，该技术可以在维持原模型精度的前提下，只取本地反向传播计算出的梯度矩阵中绝对值最大的0.1\%的梯度进行求平均的操作。因为矩阵的非零元只有0.1\%，所以这是一个稀疏矩阵。将原梯度矩阵压缩为稀疏矩阵再进行Allreduce，就可以大幅度降低通信量，减少通信时间，进而加速分布式训练的速度。

深度梯度压缩技术在通信量的压缩方面做出了很好的效果，但是从计算的角度来看，该技术仍有一些方面存在优化空间。

首先，Allreduce算法的需要执行多轮通信，并在每一轮通信结束后，将本地的梯度与从网络接收的梯度逐元素相加。若在通信时使用稀疏矩阵，则接收到稀疏矩阵后将其解压缩，再将梯度逐元素相加并再次压缩为稀疏矩阵，之后将其发送给其他进程，开始下一轮通信。这样每一轮都将浪费大量的时间在稀疏矩阵的压缩和解压缩上，同时，两个非零元极少的矩阵逐元素相加时，也会有大量冗余的零元加法。因此，我们实现了一个能让稀疏矩阵直接相加的算法，节省了大量压缩和解压缩稀疏矩阵的时间。在Allreduce算法的每一轮通信中，我们的算法不需要进行稀疏矩阵的压缩和解压缩，根据实验结果，稀疏矩阵加法所占用的时间仅为稀疏矩阵通信时间的??????\%。

其次，要想选择出绝对值最大的0.1\%的梯度，需要对原梯度矩阵进行筛选。这是一个第k大值（Top-K Value）问题，可以使用随机选择算法~\cite{IntroToAlgo}解决该问题，该算法的时间复杂度为O(n)。虽然时间复杂度较低，但在神经网络参数较多时算法执行时间仍然较长。我们利用了只需要选取梯度矩阵中第$\frac{size}{1000}$\footnote{size为梯度矩阵的元素个数}大的梯度这一特殊的性质\footnote{其特殊性在于，需要选择的不是一个$\frac{size}{2}$或$\frac{size}{3}$这样一个介于1$\sim$ size之间的较为靠近中间的排名，而是$\frac{size}{1000}$，排名非常靠前。这种特殊性所能带来好处将在第\ref{subsec:topKOptimize}节的分析中体现出来。}，先对原梯度矩阵经过采样等一系列操作后再输入随机选择算法，最终将第k大梯度选择的速度提高了?????倍。

同时，传统神经网络训练框架在进行分布式训练时一般使用的是环形Allreduce算法，但是环形算法的通信轮次数较多，延迟较大，在节点数较多时尤为严重，并不适合我们的算法。我们选择使用了通信轮次数更少的蝶形算法。

最后，我们尝试使用了一种目前仍处在试验阶段的智能网卡，智能网卡上有一个ARM处理器，可以进行较为复杂的计算操作，我们利用它可以进行计算的特性来降低通信延迟。

\section{本文的组织}

本文的剩余部分按照如下内容组织。

第\ref{chap2}章对相关研究工作进行综述，并对神经网络分布式训练与模型裁剪、常见的Allreduce算法、随机选择算法、稀疏矩阵的存储格式以及智能网卡等多方面内容进行介绍；第\ref{chap3}章对如何降低神经网络分布式训练中的Allreduce过程的时间这一课题进行研究，并提出了我们所涉及的基于深度梯度压缩技术的Allreduce算法的优化；第\ref{chap4}章根据我们提出的Allreduce优化技术设计实验并分析实验结果；第\ref{chap5}章对全文进行总结，并提出本文工作于未来的展望。